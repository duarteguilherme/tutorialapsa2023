{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc0fbe7-dc61-4749-b397-3d539e8d05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load autobounds components used in this demo\n",
    "from autobounds.causalProblem import causalProblem\n",
    "from autobounds.DAG import DAG\n",
    "from autobounds.Query import Query\n",
    "\n",
    "# load additional dependencies\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import plotnine as pn\n",
    "\n",
    "# configure plotting options\n",
    "pn.options.figure_size = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e372cd1c-2bb8-46ed-9d59-8ce782380117",
   "metadata": {},
   "source": [
    "# Estimating treatment effects under noncompliance: <br>An introduction to `autobounds`\n",
    "\n",
    "Kai Cooper, Guilherme Duarte, and Dean Knox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e97d2-782d-4db2-b954-6878cd2dc71d",
   "metadata": {},
   "source": [
    "This notebook introduces `autobounds` (Duarte et al., 2023), a method for automatically drawing principled inferences in the presence of common imperfections in data and design. It illustrates how `autobounds` can be used to obtain sharp bounds—the narrowest possible range of conclusions consistent with available, imperfect information—using the example of a randomized experiment with noncompliance\n",
    "\n",
    "- Section 1 introduces data from a hypothetical experiment with noncompliance, the running example in this notebook.\n",
    "- Section 2 states the causal effects of interest to the analyst and describes various assumptions that analysts might use.\n",
    "- Section 3 shows how to use `autobounds` to test assumptions and compute sharp bounds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a128c-61a1-4573-bb3a-3ac3140c3ddc",
   "metadata": {},
   "source": [
    "# 1. Design and data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294c7a20-84ce-4a26-b9c5-f28b60c8726c",
   "metadata": {},
   "source": [
    "Suppose that a researcher designs a randomized controlled trial (RCT) that aims to estimate the causal effect of a treatment on a binary outcome. In this RCT, 1,000 subjects are randomly assigned to two treatment groups, denoted with $Z \\in \\{0, 1\\}$. However, the RCT is affected by *noncompliance*, meaning that not all subjects obey this random assignment; let $X \\in \\{0, 1\\}$ indicate the treatment that is actually received. Finally, a binary outcome $Y \\in \\{0, 1\\}$ is measured.\n",
    "\n",
    "The researcher believes that this noncompliance may be confounded with the outcome. For example, subjects that believe that the treatment will be beneficial may not comply with assignment to the control group. In an attempt to salvage the experiment, the researcher points out that assignment $Z$ can still be regarded as an *encouragement* to take treatment, suggesting an instrumental-variables analysis. \n",
    "\n",
    "We will first present some exploratory analyses to introduce the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de961c7",
   "metadata": {},
   "source": [
    "## 1.a. Load and inspect raw data\n",
    "\n",
    "In this subsection, we will import the data and examine some summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b7e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000 rows x 3 columns\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c5f48-842c-42a1-9f95-7bfe0d4ebc4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine random sample\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2316aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine \n",
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed919f",
   "metadata": {},
   "source": [
    "That is, 35% of subjects were encouraged to take treatment, 64% received the treatment and 47% experienced the positive outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5c04f0-8ed9-4f18-888d-56afc54668a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of units with each combination of Z, X, Y\n",
    "(\n",
    "    data\n",
    "    .value_counts()\n",
    "    .sort_values()    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb16e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate informative variable names for plotting\n",
    "data = data.assign(\n",
    "    Z_label = data.Z.map({0 : \"assigned to control\", 1 : \"assigned to treatment\"}),\n",
    "    X_label = data.X.map({0 : \"received control\", 1 : \"received treatment\"}),\n",
    "    Y_label = data.Y.map({0 : \"died\", 1 : \"survived\"})\n",
    ")\n",
    "\n",
    "# create initial visualization\n",
    "(\n",
    "    pn.ggplot(data,\n",
    "              pn.aes(x = \"X_label\",\n",
    "                     fill = \"Y_label\"\n",
    "                    )\n",
    "             ) \n",
    "    + pn.facet_wrap(\"Z_label\")\n",
    "    + pn.geom_histogram(binwidth = 1, position = 'dodge')\n",
    "    + pn.ylab(\"Frequency\")\n",
    "    + pn.theme_light()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89eea23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e725fbc7",
   "metadata": {},
   "source": [
    "## 1.b. Conduct preliminary analyses\n",
    "\n",
    "In this subsection, we will conduct a preliminary regression analysis to examine the first stage (regressing treatment uptake on encouragement) and reduced form (regressing outcome on encouragement)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb2ded-805b-4f41-b618-cb6eb3b34a20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first stage regression\n",
    "model_firststage = smf.ols(\"X ~ Z\", data = data).fit()\n",
    "model_firststage.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a3a0b-6d35-411b-820d-049d32a2b0c6",
   "metadata": {},
   "source": [
    "This regression shows that that treatment assignment $Z$ is significantly associated with actual treatment uptake $X$, but receiving the encouragement actually *decreases* treatment uptake by 60 percentage points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8346ee06-e103-4091-aca3-d6d46ea9f958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first stage regression\n",
    "model_reducedform = smf.ols(\"Y ~ Z\", data = data).fit()\n",
    "model_reducedform.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eaad88-741e-4a77-8bbb-6dc46b09469a",
   "metadata": {},
   "source": [
    "This regression shows that that treatment assignment $Z$ significantly improves outcomes by 44 percentage points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84da05-f2c9-47c1-9d3f-b2594f0a734f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d5dbe-6be3-47e3-ba63-ed13ea5d2241",
   "metadata": {},
   "source": [
    "## 1.c. Prepare summary statistics\n",
    "\n",
    "Finally, we will preprocess the data. `autobounds` works with sufficient statistics that represent the proportion of units with each unique combination of values, so we will first compute these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count units with each unique combination of Z, X, Y \n",
    "data_summary = (\n",
    "    data\n",
    "    .loc[:, ['Z', 'X', 'Y']]\n",
    "    .value_counts()\n",
    "    .rename('counts')\n",
    "    .reset_index()\n",
    ")\n",
    "data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12e914b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# divide by the total to get the estimated probability of each type\n",
    "data_summary = data_summary.assign(prob = data_summary.counts / data_summary.counts.sum())\n",
    "data_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d1266f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c5009-0c5f-4eeb-b3c0-bc004ffb9c75",
   "metadata": {},
   "source": [
    "# 2. Background, assumptions, and estimands\n",
    "\n",
    "In this section, we provide brief background on the instrumental variables model, as well as a discussion of common assumptions and estimands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ef913",
   "metadata": {},
   "source": [
    "## 2.a. Background on instrumental variables in the context of `autobounds`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce43c96",
   "metadata": {},
   "source": [
    "Imbens and Angrist (1994) show that in terms of subjects' decisions to take treatment, the population can divided into four mutually exclusive groups. Note that membership in these groups cannot be directly observed.\n",
    "\n",
    "* **Never-takers:** those that will never take treatment regardless of encouragement, i.e. subjects with $X(Z=0)=0$ and $X(Z=1)=0$\n",
    "* **Compliers:** those that will only take treatment when encouraged, i.e. subjects with $X(Z=0)=0$ and $X(Z=1)=1$\n",
    "* **Defiers:** those that will only take treatment when *not* encouraged, i.e. subjects with $X(Z=0)=1$ and $X(Z=1)=0$\n",
    "* **Always-takers:** those that will never take treatment regardless of encouragement, i.e. subjects with $X(Z=0)=1$ and $X(Z=1)=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0475479d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88983d3",
   "metadata": {},
   "source": [
    "## 2.b. Common assumptions in instrumental-variables analysis\n",
    "\n",
    "Imbens and Angrist (1994) discuss a number of assumptions for the instrumental variables problems. For our purposes, the most important are:\n",
    "\n",
    "- **Unconfoundedness:** Encouragement $Z$ is not confounded with treatment uptake $X$ or outcome $Y$. Formally, this states that $Z$ is independent of $X(z)$ for any $z$ and $Y(x)$ for any $x$.\n",
    "- **Exclusion restriction:** Encouragement $Z$ does not directly affect outcome $Y$ except through treatment uptake $X$. Formally, this states that $Y(z,x)$ is the same as $Y(x)$ for all $z$ and $x$.\n",
    "- **Monotonicity:** There are no \"defier\" subjects, as defined above. Formally, this states that $X(Z=1) \\ge X(Z=0)$.\n",
    "\n",
    "Applied researchers often make all of the above assumptions without considering whether they are substantively justified in a particular setting.\n",
    "\n",
    "However, the assumptions often do not hold. In the running example, only the unconfoundedness assumption is guaranteed by the experimental design, because $Z$ is randomized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b13bca1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb4395",
   "metadata": {},
   "source": [
    "## 2.c. Common estimands in instrumental-variables analyses\n",
    "\n",
    "Most applied research seeks to identify an average treatment effect (ATE), averaging over all subjects or the population from which those subjects were drawn. Formally, the ATE is $\\mathbb{E}[Y(X=1) - Y(X=0)]$.\n",
    "\n",
    "Unfortunately, this quantity cannot be precisely estimated when there is noncompliance with treatment assignment. One intuitive reason for this is because the behavior of never-takers and always-takers is unaffected by the randomized encouragement. Therefore, the effect of treatment is fundamentally unidentifiable in these groups.\n",
    "\n",
    "If all of the above assumptions are in fact true (and if the encouragement does in fact affect treatment uptake), Imbens and Angrist (1994) show that a particular causal effect—the *local* average treatment effect (LATE) among the subgroup of compliers—can be identified using the conventional two-stage least squares estimator. Formally, the LATE is $\\mathbb{E}[Y(X=1) - Y(X=0) | X(Z=0)=0, X(Z=1)=1]$.\n",
    "\n",
    "Because the ATE generally cannot be point identified under noncompliance, it is common for applied researchers to behave as if they are uninterested in this quantity. Often, researchers claim that the purpose of the experiment was to identify the LATE instead. However, the LATE is rarely of practical importance, because  whether subjects comply with an encouragement often depends on how that encouragement was implemented in the context of a particular experiment. Moreover, LATE also cannot be point identified unless all of the assumptions described above are satisfied.\n",
    "\n",
    "Below, we will show how `autobounds` allows researchers to compute *sharp bounds*, or the narrowest possible range of conclusions that honestly acknowledge limitations and use only the assumptions that are substantively defensible, for essentially any estimand including the ATE and LATE. We will also show how `autobounds` checks assumptions and alert researchers when their observable implications are violated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174dc96d-6fc5-426a-b798-86b841248917",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c267b-c52b-4816-9d98-c02b6a6b80fd",
   "metadata": {},
   "source": [
    "# 3. Computation of effects via `autobounds`\n",
    "\n",
    "In this section, we demonstrate the use of `autobounds`. First, we demonstrate how to compute sharp bounds on the original quantity of interest, the ATE, using only assumptions that are substantively justified. Next, we show how researchers can also target the LATE by simply declaring a different estimand. Finally, we illustrate how `autobounds` can detect violations of assumptions that would be missed by traditional methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e22df-f0a5-4050-be46-b1390536735d",
   "metadata": {},
   "source": [
    "## 3.a. Bounding the ATE under plausible assumptions\n",
    "\n",
    "In this section, we will present a step-by-step demonstration of `autobounds`. As a working example, we will compute sharp bounds on the original quantity of interest, the ATE, under only the assumptions that make sense in this setting: unconfoundedness and the exclusion restriction. \n",
    "\n",
    "First, we will define the assumed directed acyclic graph (DAG). All of the plausible assumptions in this case are structural assumptions that can be represented in this graph. Instatiate an empty DAG via the `DAG` class within the package. Build the structure of the graph with the method `.from_structure()`, which takes two arguments: \n",
    "- `edges`: A comma-separated string listing pairs of connected nodes. E.g. `\"A -> B, B -> C, U -> A, U -> B\"`\n",
    "- `unob`: A comma-separated string listing the nodes that are unobserved disturbances\n",
    "\n",
    "The graph can then be visualized using its `.plot()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350effe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first initialize an empty graph\n",
    "graph = DAG()\n",
    "\n",
    "# define edges and unobserved disturbances\n",
    "graph.from_structure(\n",
    "    edges = \"Uz -> Z, Z -> X, X -> Y, Uxy -> X, Uxy -> Y\",\n",
    "    unob = \"Uz, Uxy\"\n",
    ")\n",
    "\n",
    "# visualize the graph\n",
    "graph.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe70f9",
   "metadata": {},
   "source": [
    "Second, we will tell `autobounds` about the causal-inference problem we would like to solve. A problem is defined by four elements:\n",
    "- The causal graph, or structural assumptions relating the variables\n",
    "- The sample space, or the number of unique values that each variable can take on\n",
    "- Additional functional-form assumptions justified by domain expertise\n",
    "- The empirical evidence, or the data\n",
    "- The quantity of interest, or the estimand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c675d9d",
   "metadata": {},
   "source": [
    "We will begin with the `causalProblem()` constructor, which takes two arguments:\n",
    "- `graph`: the causal structure that the problem involves\n",
    "- `number_values` (optional): a dictionary in which keys are variable names and values are variable cardinalities (binary, ternary, etc.). E.g. `\"{A : 2, B: 3}`. If left unspecified, all variables are assumed to be binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ebc904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a causal-inference problem involving the iv dag\n",
    "problem = causalProblem(\n",
    "    graph,\n",
    "    number_values = {\"Z\" : 2, \"X\" : 2, \"Y\" : 2}  # for illustration (not needed, same as defaults)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dce9b7",
   "metadata": {},
   "source": [
    "After initializing this problem, we next add the assumptions that `autobounds` should use.\n",
    "\n",
    "This includes additional non-structural assumptions like monotonicity, which can be added with the `.add_constraint()` method. In this case, the monotonicity assumption makes little sense, so we will omit it for now. Later, we will show how to add and test this assumption.\n",
    "\n",
    "Currently, we also need to tell `autobounds` about the laws of probability. This is done with the `.add_prob_constraints()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c111ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we had functional-form assumptions such as monotonicity, they would be entered here\n",
    "# problem.add_constraint(...)\n",
    "\n",
    "# tell autobounds about the laws of probability\n",
    "# (in a future update this will be handled automatically)\n",
    "problem.add_prob_constraints()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4f1a4e",
   "metadata": {},
   "source": [
    "The next step is to tell `autobounds` about the empirical evidence. The `.load_data()` method accepts summary statistics in the form of a `pandas` `DataFrame` object or a path to a CSV file. Regardless of the input format, this must contain (i) one column per variable measured in the dataset, (ii) one row per unique combination of values, and (iii) an additional column named \"prob\" indicating the proportion of units of this type. An example is given in `data_summary` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cac31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "problem.load_data(data_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb21e5",
   "metadata": {},
   "source": [
    "The last step is to define the quantity of interest: the ATE of actually receiving treatment $X$ on outcome $Y$. Below, two arguments are provided to the `.set_ate()` method:\n",
    "- `ind`: the name of the independent variable, or treatment\n",
    "- `dep`: the name of the dependent variable, or outcome\n",
    "\n",
    "There are more complex ways to define estimands, some of which will be illustrated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a5c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem.set_ate(ind = \"X\", dep = \"Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c59a0e-1a16-4da5-903e-e4ab318cc613",
   "metadata": {},
   "source": [
    "Finally, we are ready to compute bounds. To do so, we will first translate the completely specified causal-inference problem into an equivalent *optimization program*. Solving this program with a numeric optimizer (like SCIP in the example below) will produce the desired sharp bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d712cdce-8049-40ae-b489-902a064ab663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate causal inference problem into optimization program\n",
    "program = problem.write_program()\n",
    "\n",
    "# run optimisation routine, argument saves results at filename\n",
    "results = program.run_scip()\n",
    "\n",
    "# examine complete output\n",
    "# - \"dual\" bounds are guaranteed-valid causal bounds on the estimand\n",
    "# - \"primal\" bounds are used to evaluate the sharpness of those bounds\n",
    "# when the duals are equal to the primals, the reported bounds are perfectly sharp\n",
    "# for more details, including the interpretation of theta and epsilon, see Duarte et al (2023)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51252d27-96ca-4be0-9948-73b9ff076fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Based on these data and assumptions, the ATE is in the range [{lower:0.3f}, {upper:0.3f}]\".format(\n",
    "    lower = results[0][\"dual\"],  # index [0] selects lower bound, key [\"dual\"] selects guaranteed-valid bound\n",
    "    upper = results[1][\"dual\"],  # index [1] selects upper bound, key [\"dual\"] selects guaranteed-valid bound\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df71409e-8472-4b57-86f4-c0d0a6d35249",
   "metadata": {},
   "source": [
    "In other words, based on assumptions that are highly plausible, analysts can determine that the effect of the treatment is strongly negative despite severe noncompliance in the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638da57-389e-4d22-8c5e-eb6d27627771",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf28f60-c928-488c-b97d-4fb64ddc829b",
   "metadata": {},
   "source": [
    "## 3.b. Bounding the LATE under plausible assumptions\n",
    "\n",
    "What if we are actually interested in the LATE among compliers after all? `autobounds` is modular and simple to use: to bound this quantity, we can simply reuse the same code but state a different estimand: the *conditional* effect among compliers, or subjects with $X(Z=0)=0$ and $X(Z=1)=1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5a8a8-d008-4d92-a352-90d17766ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a causal-inference problem involving the iv dag\n",
    "problem_late = causalProblem(graph)\n",
    "\n",
    "# tell autobounds about the laws of probability\n",
    "# (in a future update this will be handled automatically)\n",
    "problem_late.add_prob_constraints()\n",
    "\n",
    "# load in the data\n",
    "problem_late.load_data(data_summary)\n",
    "\n",
    "# we now target the conditional ate among compliers  <-- THIS IS THE ONLY LINE THAT DIFFERS FROM 3.A\n",
    "problem_late.set_ate(ind = \"X\", dep = \"Y\", cond = \"X(Z=0)=0 & X(Z=1)=1\")\n",
    "\n",
    "# translate causal inference problem into optimization program\n",
    "program_late = problem_late.write_program()\n",
    "\n",
    "# run optimisation routine, argument saves results at filename\n",
    "results_late = program_late.run_scip()\n",
    "\n",
    "\"Based on these data and assumptions, the ATE is in the range [{lower:0.3f}, {upper:0.3f}]\".format(\n",
    "    lower = results_late[0][\"dual\"],  # index [0] corresponds to lower bound, dual is the guaranteed-valid bound\n",
    "    upper = results_late[1][\"dual\"],  # index [1] corresponds to lower bound, dual is the guaranteed-valid bound\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c586d0-9b6f-4634-ac98-c555ea698cf3",
   "metadata": {},
   "source": [
    "In other words, the experiment is completely uninformative about the LATE: the bounds cover the entire region of possible values, from $-1$ to $1$! (Note that the bounds computed above are slightly wider due to default numeric tolerance settings that can be adjusted.)\n",
    "\n",
    "Intuitively, this is because there is no way to determine who the compliers are, or even how large the complier group is, without additional assumptions. To identify the size of the complier group, an additional monotonicity assumption is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a1e668-00e4-4504-93b1-040d609c985b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49017837-5a05-4a6b-ad4f-d67e577bd83b",
   "metadata": {},
   "source": [
    "## 3.c. Testing observable implications of your theory\n",
    "\n",
    "What happens if analysts make a bad assumption? Here, we will illustrate how `autobounds` tests all observable implications of your assumed theory—both structural and functional assumptions—and alerts analysts to violations. \n",
    "\n",
    "To do so, we will impose the monotonicity assumption that is commonly used in instrumental-variables analyses, despite the fact that it makes little sense in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8962f9-0b0e-42cb-8705-8fa5c0d4534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a causal-inference problem involving the iv dag\n",
    "problem_badtheory = causalProblem(graph)\n",
    "\n",
    "# tell autobounds about the laws of probability\n",
    "# (in a future update this will be handled automatically)\n",
    "problem_badtheory.add_prob_constraints()\n",
    "\n",
    "# add the monotonicity assumption  <-- THIS IS THE ONLY LINE THAT DIFFERS FROM 3.A\n",
    "# by default, .add_constraint() makes the size of the stated group equal to zero \n",
    "defiers = problem_badtheory.query(\"X(Z=0)=1 & X(Z=1)=0\")\n",
    "problem_badtheory.add_constraint(defiers) # pr(defiers) == 0\n",
    "\n",
    "# load in the data\n",
    "problem_badtheory.load_data(data_summary)\n",
    "\n",
    "# we will target the unconditional ate for illustration; targeting the late produces the same result\n",
    "problem_badtheory.set_ate(ind = \"X\", dep = \"Y\")\n",
    "\n",
    "# translate causal inference problem into optimization program\n",
    "program_badtheory = problem_badtheory.write_program()\n",
    "\n",
    "# run optimisation routine, argument saves results at filename\n",
    "results_badtheory = program_badtheory.run_scip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d04b791-d8a2-4412-aee7-d82968d21402",
   "metadata": {},
   "source": [
    "This problem is *infeasible*, meaning that `autobounds` cannot find any data-generating processes that are consistent with both the stated assumptions and the empirical evidence. This means that the observable implications of the assumptions are violated. In other words, `autobounds` can prevent researchers from making claims based on demonstrably false premises!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8133ec-e90b-41bf-b686-fa4c4434303a",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc0c805-e181-4496-9941-e805b6aff656",
   "metadata": {},
   "source": [
    "Guilherme Duarte, Noam Finkelstein, Dean Knox, Jonathan Mummolo, and Ilya Shpitser. 2023. \"An Automated Approach to Causal Inference in Discrete Settings,\" *Journal of the American Statistical Association* (Theory and Methods). https://doi.org/10.1080/01621459.2023.2216909\n",
    "\n",
    "Guido Imbens and Joshua Angrist. 1994. \"Identification and Estimation of Local Average Treatment Effects,\" *Econometrica* https://doi.org/10.2307/2951620\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
